{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":191501,"sourceType":"datasetVersion","datasetId":82373},{"sourceId":2952603,"sourceType":"datasetVersion","datasetId":1794080}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"41cc4651","cell_type":"code","source":"# Save full model\nbest_model.save(os.path.join(OUTPUT_DIR, 'traffic_sign_cnn_full.h5'))\nprint(\"Full model saved.\")","metadata":{},"outputs":[],"execution_count":null},{"id":"32146a68","cell_type":"markdown","source":"## 7. Save Model for Deployment\nSave the entire model for easy loading in other scripts.","metadata":{}},{"id":"b0e8182b","cell_type":"code","source":"def predict_image(image_path, model):\n    try:\n        img = cv2.imread(image_path)\n        if img is None: return None, None\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = preprocess_img(img)\n        img = np.expand_dims(img, axis=0)\n        \n        preds = model.predict(img)\n        class_id = np.argmax(preds)\n        confidence = np.max(preds)\n        return class_id, confidence\n    except Exception as e:\n        print(e)\n        return None, None\n\n# Load best model\nbest_model = load_model(os.path.join(OUTPUT_DIR, 'best_traffic_sign_model.h5'))\n\n\ntest_img_path = \"/kaggle/input/traffic-sign-dataset-classification/traffic_Data/TEST/007_0002_j.png\"\nclass_id, conf = predict_image(test_img_path, best_model)\nprint(f\"Predicted Class: {class_id} with confidence {conf:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T15:32:48.651556Z","iopub.execute_input":"2025-11-26T15:32:48.652138Z","iopub.status.idle":"2025-11-26T15:32:49.451007Z","shell.execute_reply.started":"2025-11-26T15:32:48.652105Z","shell.execute_reply":"2025-11-26T15:32:49.450440Z"}},"outputs":[{"name":"stderr","text":"WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step\nPredicted Class: 5 with confidence 1.00\n","output_type":"stream"}],"execution_count":17},{"id":"5bcaa88c","cell_type":"markdown","source":"## 6. Inference Example\nLoad the best model and run inference on a sample image.\nWe must apply the same preprocessing (Resize + Histogram Eq) before inference.","metadata":{}},{"id":"7532d526","cell_type":"code","source":"# Callbacks\ncallbacks = [\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n    ModelCheckpoint(os.path.join(OUTPUT_DIR, 'best_traffic_sign_model.h5'), monitor='val_accuracy', save_best_only=True, verbose=1),\n    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n]\n\n# Training\nprint(\"Starting Training...\")\nhistory = model.fit(\n    aug.flow(X_train, y_train, batch_size=BATCH_SIZE),\n    validation_data=(X_val, y_val),\n    steps_per_epoch=len(X_train) // BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    verbose=1\n)\n\nprint(\"Training Complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T15:14:15.251409Z","iopub.execute_input":"2025-11-26T15:14:15.252187Z","iopub.status.idle":"2025-11-26T15:25:19.831758Z","shell.execute_reply.started":"2025-11-26T15:14:15.252161Z","shell.execute_reply":"2025-11-26T15:25:19.831169Z"}},"outputs":[{"name":"stdout","text":"Starting Training...\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1764170060.330751     117 service.cc:148] XLA service 0x7acaf000c6e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1764170060.331548     117 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1764170061.067314     117 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  5/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.9972 - loss: 0.0457 ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764170067.433562     117 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9872 - loss: 0.1019\nEpoch 1: val_accuracy improved from -inf to 0.99722, saving model to ./output/best_traffic_sign_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 63ms/step - accuracy: 0.9872 - loss: 0.1019 - val_accuracy: 0.9972 - val_loss: 0.0423 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0332","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2: val_accuracy did not improve from 0.99722\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0332 - val_accuracy: 0.9971 - val_loss: 0.0423 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9952 - loss: 0.0504\nEpoch 3: val_accuracy improved from 0.99722 to 0.99951, saving model to ./output/best_traffic_sign_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9952 - loss: 0.0504 - val_accuracy: 0.9995 - val_loss: 0.0342 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0327\nEpoch 4: val_accuracy did not improve from 0.99951\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0327 - val_accuracy: 0.9995 - val_loss: 0.0342 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9974 - loss: 0.0421\nEpoch 5: val_accuracy did not improve from 0.99951\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9974 - loss: 0.0421 - val_accuracy: 0.9995 - val_loss: 0.0333 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0375\nEpoch 6: val_accuracy did not improve from 0.99951\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0375 - val_accuracy: 0.9995 - val_loss: 0.0333 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9983 - loss: 0.0380\nEpoch 7: val_accuracy improved from 0.99951 to 0.99984, saving model to ./output/best_traffic_sign_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9983 - loss: 0.0380 - val_accuracy: 0.9998 - val_loss: 0.0317 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0397\nEpoch 8: val_accuracy did not improve from 0.99984\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0397 - val_accuracy: 0.9998 - val_loss: 0.0317 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9989 - loss: 0.0350\nEpoch 9: val_accuracy improved from 0.99984 to 1.00000, saving model to ./output/best_traffic_sign_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9989 - loss: 0.0350 - val_accuracy: 1.0000 - val_loss: 0.0308 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0314\nEpoch 10: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0314 - val_accuracy: 1.0000 - val_loss: 0.0308 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9987 - loss: 0.0362\nEpoch 11: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 47ms/step - accuracy: 0.9987 - loss: 0.0362 - val_accuracy: 1.0000 - val_loss: 0.0303 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0304\nEpoch 12: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0304 - val_accuracy: 1.0000 - val_loss: 0.0303 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9991 - loss: 0.0341\nEpoch 13: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9991 - loss: 0.0341 - val_accuracy: 1.0000 - val_loss: 0.0298 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0299\nEpoch 14: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0299 - val_accuracy: 1.0000 - val_loss: 0.0298 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9987 - loss: 0.0356\nEpoch 15: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9987 - loss: 0.0356 - val_accuracy: 1.0000 - val_loss: 0.0294 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0295\nEpoch 16: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0295 - val_accuracy: 1.0000 - val_loss: 0.0294 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9990 - loss: 0.0331\nEpoch 17: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9990 - loss: 0.0331 - val_accuracy: 0.9998 - val_loss: 0.0290 - learning_rate: 1.0000e-04\nEpoch 18/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0288\nEpoch 18: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0288 - val_accuracy: 0.9998 - val_loss: 0.0292 - learning_rate: 1.0000e-04\nEpoch 19/50\n\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9989 - loss: 0.0325\nEpoch 19: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9989 - loss: 0.0325 - val_accuracy: 0.9998 - val_loss: 0.0285 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0331\nEpoch 20: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0331 - val_accuracy: 0.9998 - val_loss: 0.0285 - learning_rate: 1.0000e-04\nEpoch 21/50\n\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9992 - loss: 0.0308\nEpoch 21: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9992 - loss: 0.0308 - val_accuracy: 0.9998 - val_loss: 0.0281 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0287\nEpoch 22: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0287 - val_accuracy: 0.9998 - val_loss: 0.0281 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9993 - loss: 0.0305\nEpoch 23: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9993 - loss: 0.0305 - val_accuracy: 1.0000 - val_loss: 0.0272 - learning_rate: 1.0000e-04\nEpoch 24/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0297\nEpoch 24: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0297 - val_accuracy: 1.0000 - val_loss: 0.0272 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9993 - loss: 0.0297\nEpoch 25: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9993 - loss: 0.0297 - val_accuracy: 1.0000 - val_loss: 0.0267 - learning_rate: 1.0000e-04\nEpoch 26/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0272\nEpoch 26: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0272 - val_accuracy: 1.0000 - val_loss: 0.0267 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9993 - loss: 0.0293\nEpoch 27: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.9993 - loss: 0.0293 - val_accuracy: 1.0000 - val_loss: 0.0263 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0265\nEpoch 28: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0265 - val_accuracy: 1.0000 - val_loss: 0.0263 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9996 - loss: 0.0280\nEpoch 29: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 47ms/step - accuracy: 0.9996 - loss: 0.0280 - val_accuracy: 0.9998 - val_loss: 0.0260 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0273\nEpoch 30: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0273 - val_accuracy: 0.9998 - val_loss: 0.0260 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9997 - loss: 0.0274\nEpoch 31: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9997 - loss: 0.0274 - val_accuracy: 1.0000 - val_loss: 0.0252 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0253\nEpoch 32: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0253 - val_accuracy: 1.0000 - val_loss: 0.0252 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9989 - loss: 0.0287\nEpoch 33: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9989 - loss: 0.0287 - val_accuracy: 1.0000 - val_loss: 0.0250 - learning_rate: 1.0000e-04\nEpoch 34/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0258\nEpoch 34: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0258 - val_accuracy: 1.0000 - val_loss: 0.0250 - learning_rate: 1.0000e-04\nEpoch 35/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9996 - loss: 0.0274\nEpoch 35: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9996 - loss: 0.0274 - val_accuracy: 0.9998 - val_loss: 0.0249 - learning_rate: 1.0000e-04\nEpoch 36/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0250\nEpoch 36: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\nEpoch 36: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0250 - val_accuracy: 0.9998 - val_loss: 0.0249 - learning_rate: 1.0000e-04\nEpoch 37/50\n\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9993 - loss: 0.0272\nEpoch 37: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9993 - loss: 0.0272 - val_accuracy: 1.0000 - val_loss: 0.0242 - learning_rate: 5.0000e-05\nEpoch 38/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0245\nEpoch 38: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0245 - val_accuracy: 1.0000 - val_loss: 0.0242 - learning_rate: 5.0000e-05\nEpoch 39/50\n\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9997 - loss: 0.0256\nEpoch 39: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9997 - loss: 0.0256 - val_accuracy: 1.0000 - val_loss: 0.0238 - learning_rate: 5.0000e-05\nEpoch 40/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0243\nEpoch 40: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 1.0000 - val_loss: 0.0238 - learning_rate: 5.0000e-05\nEpoch 41/50\n\u001b[1m540/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9995 - loss: 0.0257\nEpoch 41: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9995 - loss: 0.0257 - val_accuracy: 1.0000 - val_loss: 0.0234 - learning_rate: 5.0000e-05\nEpoch 42/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0236\nEpoch 42: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0234 - learning_rate: 5.0000e-05\nEpoch 43/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9997 - loss: 0.0245\nEpoch 43: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9997 - loss: 0.0245 - val_accuracy: 1.0000 - val_loss: 0.0230 - learning_rate: 5.0000e-05\nEpoch 44/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0242\nEpoch 44: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0242 - val_accuracy: 1.0000 - val_loss: 0.0230 - learning_rate: 5.0000e-05\nEpoch 45/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9995 - loss: 0.0248\nEpoch 45: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9995 - loss: 0.0248 - val_accuracy: 1.0000 - val_loss: 0.0227 - learning_rate: 5.0000e-05\nEpoch 46/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9844 - loss: 0.1027\nEpoch 46: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9844 - loss: 0.1027 - val_accuracy: 1.0000 - val_loss: 0.0227 - learning_rate: 5.0000e-05\nEpoch 47/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9997 - loss: 0.0241\nEpoch 47: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9997 - loss: 0.0241 - val_accuracy: 1.0000 - val_loss: 0.0223 - learning_rate: 5.0000e-05\nEpoch 48/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0224\nEpoch 48: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0223 - learning_rate: 5.0000e-05\nEpoch 49/50\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9997 - loss: 0.0238\nEpoch 49: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.9997 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 0.0219 - learning_rate: 5.0000e-05\nEpoch 50/50\n\u001b[1m  1/541\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0224\nEpoch 50: val_accuracy did not improve from 1.00000\n\u001b[1m541/541\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0219 - learning_rate: 5.0000e-05\nRestoring model weights from the end of the best epoch: 50.\nTraining Complete.\n","output_type":"stream"}],"execution_count":10},{"id":"b888b654","cell_type":"markdown","source":"## 5. Training Loop\nWe use Keras `model.fit` with callbacks for:\n1.  **ReduceLROnPlateau**: Reduce learning rate when validation loss stops improving.\n2.  **ModelCheckpoint**: Save the best model based on validation accuracy.\n3.  **EarlyStopping**: Stop training if no improvement for 10 epochs.","metadata":{}},{"id":"f905b57a","cell_type":"code","source":"class TrafficSignsNet:\n    @staticmethod\n    def build(width, height, numClasses, finalAct=\"softmax\"):\n        inputShape = (height, width, 3)\n        chanDim = -1\n        weight_decay = 1e-4\n        \n        inputs = Input(shape=inputShape)\n        \n        # (CONV => RELU) * 2 => POOL \n        # 48x48\n        x = Conv2D(32, (3, 3), padding=\"same\", kernel_regularizer=l2(weight_decay))(inputs)\n        x = BatchNormalization(axis=chanDim)(x)\n        x = Activation(\"relu\")(x)\n        x = Conv2D(32, (3, 3), padding=\"same\", kernel_regularizer=l2(weight_decay))(x)\n        x = BatchNormalization(axis=chanDim)(x)\n        x = Activation(\"relu\")(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.2)(x)\n        \n        # (CONV => RELU) * 2 => POOL\n        # 24x24\n        x = Conv2D(64, (3, 3), padding=\"same\", kernel_regularizer=l2(weight_decay))(x)\n        x = BatchNormalization(axis=chanDim)(x)\n        x = Activation(\"relu\")(x)\n        x = Conv2D(64, (3, 3), padding=\"same\", kernel_regularizer=l2(weight_decay))(x)\n        x = BatchNormalization(axis=chanDim)(x)\n        x = Activation(\"relu\")(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.2)(x)\n        \n        # (CONV => RELU) * 2 => POOL\n        # 12x12\n        x = Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(weight_decay))(x)\n        x = BatchNormalization(axis=chanDim)(x)\n        x = Activation(\"relu\")(x)\n        x = Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(weight_decay))(x)\n        x = BatchNormalization(axis=chanDim)(x)\n        x = Activation(\"relu\")(x)\n        x = MaxPooling2D(pool_size=(2, 2))(x)\n        x = Dropout(0.35)(x)\n        \n        # Flatten and Dense\n        x = Flatten()(x)\n        x = Dense(256, kernel_regularizer=l2(weight_decay))(x)\n        x = BatchNormalization()(x)\n        x = Activation(\"relu\")(x)\n        x = Dropout(0.5)(x)\n        x = Dense(numClasses, kernel_regularizer=l2(weight_decay))(x)\n        x = Activation(finalAct, name=\"class_output\")(x)\n        \n        model = Model(inputs=inputs, outputs=x, name=\"trafficSignsNet\")\n        return model\n\n# Build Model\nmodel = TrafficSignsNet.build(width=IMG_SIZE, height=IMG_SIZE, numClasses=NUM_CLASSES)\n\n# Load Pretrained Weights\nprint(f\"Loading weights from {WEIGHTS_PATH}...\")\ntry:\n    model.load_weights(WEIGHTS_PATH)\n    print(\"Weights loaded successfully!\")\nexcept Exception as e:\n    print(f\"Error loading weights: {e}\")\n    print(\"Ensure the architecture matches exactly.\")\n\n# Compile\nopt = Adam(learning_rate=LEARNING_RATE, decay=LEARNING_RATE / EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T15:13:47.746830Z","iopub.execute_input":"2025-11-26T15:13:47.747660Z","iopub.status.idle":"2025-11-26T15:13:49.214795Z","shell.execute_reply.started":"2025-11-26T15:13:47.747633Z","shell.execute_reply":"2025-11-26T15:13:49.214253Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1764170027.855926      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Loading weights from ./output/german_aug-99.37.h5...\nWeights loaded successfully!\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"trafficSignsNet\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"trafficSignsNet\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,179,904\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)             │        \u001b[38;5;34m11,051\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ class_output (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,051</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ class_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,480,779\u001b[0m (5.65 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,480,779</span> (5.65 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,479,371\u001b[0m (5.64 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,479,371</span> (5.64 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"id":"430b7d91","cell_type":"markdown","source":"## 4. Model Definition (TrafficSignsNet)\nWe define the custom CNN architecture used by the pre-trained model.\nThis architecture consists of 3 blocks of (Conv -> BN -> Relu) x 2 -> Pool, followed by a fully connected head.\nWe then load the pre-trained weights (`german_aug-99.37.h5`) to initialize the model.","metadata":{}},{"id":"07e45cca","cell_type":"code","source":"# Data Augmentation\naug = ImageDataGenerator(\n    rotation_range=10,\n    zoom_range=0.15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.15,\n    horizontal_flip=False,\n    vertical_flip=False,\n    fill_mode=\"nearest\"\n)\n\nprint(\"Data Augmentation initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T15:13:40.466758Z","iopub.execute_input":"2025-11-26T15:13:40.467672Z","iopub.status.idle":"2025-11-26T15:13:40.472175Z","shell.execute_reply.started":"2025-11-26T15:13:40.467643Z","shell.execute_reply":"2025-11-26T15:13:40.471368Z"}},"outputs":[{"name":"stdout","text":"Data Augmentation initialized.\n","output_type":"stream"}],"execution_count":8},{"id":"453d1da6","cell_type":"markdown","source":"## 3. Data Augmentation\nWe use Keras `ImageDataGenerator` for real-time data augmentation during training.\nThis helps the model generalize better by seeing slightly modified versions of the images.","metadata":{}},{"id":"3c0407ab","cell_type":"code","source":"# Preprocessing function from the original repo\ndef preprocess_img(img):\n    # Histogram normalization in y channel\n    hsv = color.rgb2hsv(img)\n    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n    img = color.hsv2rgb(hsv)\n    # Resize\n    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n    return img\n\n# Class Mapping\ncustom_to_gtsrb_map = {\n    2: 1,   # Speed limit (30km/h)\n    4: 2,   # Speed limit (50km/h)\n    5: 3,   # Speed limit (60km/h)\n    6: 4,   # Speed limit (70km/h)\n    7: 5,   # Speed limit (80km/h)\n    19: 2,  # Speed limit (50km/h)\n    20: 36, # Go straight or right\n    21: 35, # Go straight\n    22: 34, # Go Left -> Turn left ahead\n    24: 33, # Go Right -> Turn right ahead\n    25: 39, # keep Left\n    26: 38, # keep Right\n    27: 40, # Roundabout mandatory\n    30: 29, # Bicycles crossing\n    33: 26, # Traffic signals\n    34: 18, # Danger Ahead -> General caution\n    35: 27, # Zebra Crossing -> Pedestrians\n    36: 29, # Bicycles crossing\n    37: 28, # Children crossing\n    38: 19, # Dangerous curve to the left\n    39: 20, # Dangerous curve to the right\n    43: 36, # Go right or straight\n    44: 37, # Go left or straight\n    46: 21, # ZigZag Curve -> Double curve\n    48: 25  # Under Construction -> Road work\n}\n\ndef load_data():\n    data = []\n    labels = []\n    \n    # 1. Load GTSRB Data\n    print(\"Loading GTSRB Data...\")\n    gtsrb_train_csv = os.path.join(GTSRB_ROOT, 'Train.csv')\n    if os.path.exists(gtsrb_train_csv):\n        df = pd.read_csv(gtsrb_train_csv)\n        # Limit for testing if needed, but full training is requested\n        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"GTSRB\"):\n            img_path = os.path.join(GTSRB_ROOT, row['Path'])\n            try:\n                img = cv2.imread(img_path)\n                if img is not None:\n                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                    img = preprocess_img(img)\n                    data.append(img)\n                    labels.append(int(row['ClassId']))\n            except Exception as e:\n                pass\n    \n    # 2. Load Custom Dataset\n    print(\"Loading Custom Dataset...\")\n    if os.path.exists(CUSTOM_DS_ROOT):\n        for custom_id_str in tqdm(os.listdir(CUSTOM_DS_ROOT), desc=\"Custom\"):\n            try:\n                custom_id = int(custom_id_str)\n            except ValueError:\n                continue\n            \n            if custom_id in custom_to_gtsrb_map:\n                target_gtsrb_id = custom_to_gtsrb_map[custom_id]\n                class_dir = os.path.join(CUSTOM_DS_ROOT, custom_id_str)\n                for img_name in os.listdir(class_dir):\n                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n                        full_path = os.path.join(class_dir, img_name)\n                        try:\n                            img = cv2.imread(full_path)\n                            if img is not None:\n                                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                                img = preprocess_img(img)\n                                data.append(img)\n                                labels.append(target_gtsrb_id)\n                        except:\n                            pass\n                            \n    data = np.array(data, dtype='float32')\n    labels = np.array(labels)\n    \n    # One-hot encoding\n    labels = tf.keras.utils.to_categorical(labels, NUM_CLASSES)\n    \n    return data, labels\n\nX, y = load_data()\nprint(f\"Total samples: {len(X)}\")\n\n# Split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\nprint(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T15:07:25.837867Z","iopub.execute_input":"2025-11-26T15:07:25.838191Z","iopub.status.idle":"2025-11-26T15:13:35.479821Z","shell.execute_reply.started":"2025-11-26T15:07:25.838167Z","shell.execute_reply":"2025-11-26T15:13:35.479157Z"}},"outputs":[{"name":"stdout","text":"Loading GTSRB Data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"GTSRB:   0%|          | 0/39209 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e96fc6384154513a888ab87b92e4476"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/skimage/color/colorconv.py:330: RuntimeWarning: divide by zero encountered in divide\n  out[idx, 0] = 4.0 + (arr[idx, 0] - arr[idx, 1]) / delta[idx]\n/usr/local/lib/python3.11/dist-packages/skimage/color/colorconv.py:322: RuntimeWarning: divide by zero encountered in divide\n  out[idx, 0] = (arr[idx, 1] - arr[idx, 2]) / delta[idx]\n/usr/local/lib/python3.11/dist-packages/skimage/color/colorconv.py:326: RuntimeWarning: divide by zero encountered in divide\n  out[idx, 0] = 2.0 + (arr[idx, 2] - arr[idx, 0]) / delta[idx]\n","output_type":"stream"},{"name":"stdout","text":"Loading Custom Dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Custom:   0%|          | 0/58 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b9db5c87a6e4697b3eeaa00006793f6"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/skimage/color/colorconv.py:316: RuntimeWarning: divide by zero encountered in divide\n  out_s = delta / out_v\n","output_type":"stream"},{"name":"stdout","text":"Total samples: 40757\nTrain shape: (34643, 48, 48, 3), Val shape: (6114, 48, 48, 3)\n","output_type":"stream"}],"execution_count":7},{"id":"99df91a6","cell_type":"markdown","source":"## 2. Data Loading and Preprocessing\nWe load both GTSRB and the Custom Dataset.\n**Crucial Step**: We apply the same preprocessing as the original model (Histogram Equalization in HSV space) to ensure the pre-trained weights work correctly.\nImages are resized to **48x48**.","metadata":{}},{"id":"0a5828b6","cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, Dense, Flatten, Input\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom skimage import color, exposure, transform\nimport requests\nfrom tqdm.notebook import tqdm\n\n# Configuration\nIMG_SIZE = 48 # Model expects 48x48\nNUM_CLASSES = 43\nBATCH_SIZE = 64\nEPOCHS = 50\nLEARNING_RATE = 1e-4\n\n# Paths\nGTSRB_ROOT = '/kaggle/input/gtsrb-german-traffic-sign'\nCUSTOM_DS_ROOT = '/kaggle/input/traffic-sign-dataset-classification/traffic_Data/DATA'\nOUTPUT_DIR = './output'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Pretrained Weights URL\nWEIGHTS_URL = \"https://github.com/citlag/European-Traffic-Sings/raw/master/models/cnn_8-layers_improved/GTSRB_weights/german_aug-99.37.h5\"\nWEIGHTS_PATH = os.path.join(OUTPUT_DIR, 'german_aug-99.37.h5')\n\nprint(f\"TensorFlow Version: {tf.__version__}\")\nprint(f\"Using GPU: {len(tf.config.list_physical_devices('GPU')) > 0}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T15:07:21.747549Z","iopub.execute_input":"2025-11-26T15:07:21.748332Z","iopub.status.idle":"2025-11-26T15:07:21.754919Z","shell.execute_reply.started":"2025-11-26T15:07:21.748303Z","shell.execute_reply":"2025-11-26T15:07:21.754244Z"}},"outputs":[{"name":"stdout","text":"TensorFlow Version: 2.18.0\nUsing GPU: True\n","output_type":"stream"}],"execution_count":6},{"id":"ea72f204","cell_type":"code","source":"# Download Pretrained Weights\nif not os.path.exists(WEIGHTS_PATH):\n    print(f\"Downloading weights from {WEIGHTS_URL}...\")\n    try:\n        response = requests.get(WEIGHTS_URL)\n        response.raise_for_status()\n        with open(WEIGHTS_PATH, 'wb') as f:\n            f.write(response.content)\n        print(\"Download complete.\")\n    except Exception as e:\n        print(f\"Error downloading weights: {e}\")\nelse:\n    print(f\"Weights file already exists at {WEIGHTS_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T15:01:34.046555Z","iopub.execute_input":"2025-11-26T15:01:34.046759Z","iopub.status.idle":"2025-11-26T15:01:34.051075Z","shell.execute_reply.started":"2025-11-26T15:01:34.046743Z","shell.execute_reply":"2025-11-26T15:01:34.050402Z"}},"outputs":[{"name":"stdout","text":"Weights file already exists at ./output/german_aug-99.37.h5\n","output_type":"stream"}],"execution_count":5},{"id":"fd946ff2","cell_type":"markdown","source":"# Traffic Sign Classification Training\nThis notebook trains a high-accuracy traffic sign classifier using the GTSRB dataset and a custom dataset.\nIt is designed to run on Kaggle with a P100 GPU.\n\n## 1. Imports and Setup","metadata":{}}]}